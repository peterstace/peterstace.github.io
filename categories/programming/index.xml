<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Programming on Peter Stace&#39;s Personal Blog</title>
    <link>http://peterstace.io/categories/programming/index.xml</link>
    <description>Recent content in Programming on Peter Stace&#39;s Personal Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <atom:link href="http://peterstace.io/categories/programming/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Path Tracing Part 3 - Acceleration Structure</title>
      <link>http://peterstace.io/post/2017-01-04-path-tracing-part-03-acceleration-structure/</link>
      <pubDate>Wed, 04 Jan 2017 09:21:37 +1100</pubDate>
      
      <guid>http://peterstace.io/post/2017-01-04-path-tracing-part-03-acceleration-structure/</guid>
      <description>

&lt;p&gt;I recently added an acceleration data structure to my &lt;a href=&#34;https://github.com/peterstace/grayt&#34;&gt;path
tracer&lt;/a&gt;. This resulted in a large
performance improvement.&lt;/p&gt;

&lt;p&gt;The acceleration structure improves the speed of the &lt;em&gt;global ray intersection
test&lt;/em&gt;, an integral part of any path tracer.&lt;/p&gt;

&lt;p&gt;The source code can be found
&lt;a href=&#34;https://github.com/peterstace/grayt/blob/master/grayt/grid.go&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;global-ray-intersection-test&#34;&gt;Global Ray Intersection Test&lt;/h2&gt;

&lt;p&gt;The global ray intersection test is the most computationally expensive part of
a path tracer. The test takes a ray, and checks to see if it intersects with
any of the objects in the scene.&lt;/p&gt;

&lt;p&gt;A &lt;code&gt;ray&lt;/code&gt; is defined as an origin &lt;code&gt;vector&lt;/code&gt; and a (unit) direction &lt;code&gt;vector&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type vector { x, y, z float64 }

type ray { origin, dir float64 }
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Objects in the scene are defined as:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type object interface {
    intersect(ray) (unitNormal vector, distance float64, hit bool)
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the &lt;code&gt;ray&lt;/code&gt; intersects the object, then &lt;code&gt;intersect(ray)&lt;/code&gt; will return the unit
normal at the hit site, along with the distance to the hit site from the ray
origin.&lt;/p&gt;

&lt;p&gt;To calculate the intersection between a ray and all objects in the scene, we
must complete the following code:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type dataStructure struct {
    // ...
}

func newDataStructure([]object) *dataStructure {
    // ...
}

func (d *dataStructure) intersect(r ray) (unitNormal vector, distance float64, hit bool) {
    // ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There are lots of different ways to implement the global ray intersection test,
and performance will always be an important consideration. This is because:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;The global ray intersection test has to be executed a large number of times.
In a path tracer, each ray cast from the camera may spawn 10s of secondary
rays (e.g. reflection rays). So even with a modest image resolution (1000 by
1000 pixels) and a modest sample rate (1000 samples per pixel), it&amp;rsquo;s possible
that upwards to 10 billion ray intersection will be required to render a single
image.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;A single global ray intersection test itself is computationally expensive. It
must consider all of the objects in the scene. There may be 100s of thousands
of objects in the scene.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;naive-implementation&#34;&gt;Naive Implementation&lt;/h2&gt;

&lt;p&gt;The naive implementation sequentially checks each object in the scene, keeping
track of the closest intersection found so far. This is easy to implement, but
has the worst possible performance.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;type objectList struct {
    objs []object
}

func newObjectList(objs []object) *objectList {
    return &amp;amp;objectList{objs}
}

func (o *objectList) intersect(r ray) (unitNormal vector, distance float64, hit bool) {

    closest struct {
        unitNormal vector
        distance   float64
        hit        bool
    }

    for _, obj := range o.objs {
        unitNormal, distance, hit := obj.intersect(r)
        if !hit {
            continue
        }
        if !closest.hit || distance &amp;lt; closest.distance {
            closest.unitNormal = unitNormal
            closest.distance = distance
            closest.hit = true
        }
    }

    return closest.unitNormal, closest.distance, closest.hit
}

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The main problem with the naive implementation is that it has to check each
object in the scene for an intersection. If we can reduce the amount of
intersection tests with individual objects, we can increase the overall
performance.&lt;/p&gt;

&lt;h2 id=&#34;fast-implementation&#34;&gt;Fast Implementation&lt;/h2&gt;

&lt;p&gt;A &amp;ldquo;grid&amp;rdquo; data structure can allow us to dramatically increase the speed of the
global ray intersection test. It does this by cleverly reducing the number of
individual object intersections tests we have to perform.&lt;/p&gt;

&lt;p&gt;The algorithm is split into two parts:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The data structure is populated using the set of objects in the scene.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The data structure is then traversed to solve the global ray intersection
test.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;grid-population&#34;&gt;Grid Population&lt;/h3&gt;

&lt;p&gt;First a 3D grid created, the same size as the scene. Each object in the scene
is checked to see which grid cell(s) it falls into. The objects are then stored
into an array representing the grid for fast access. This data structure allows
the list of scene objects in a given grid cell to be accessed in constant
time.&lt;/p&gt;

&lt;p&gt;A 2D example is shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://peterstace.io/static/images/grid/grid.svg&#34; alt=&#34;Grid Population&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;grid-traversal&#34;&gt;Grid Traversal&lt;/h3&gt;

&lt;p&gt;When performing the global ray intersection test, the first step is the find
the cell in the grid that is first hit by the ray. Each scene object in that
cell is then tested for a ray intersection. If any of the objects in that cell
intersect with the ray, then the result of the global ray intersection test is
the intersection with the individual object that&amp;rsquo;s closest to the start of the
ray. If no object is detected, then we continue to the next cell and repeat.
The global ray intersection check finishes when an intersection has been found
or we have traversed all the way to the other side of the grid.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a non-obvious edge case that must be accounted for. An object may be
partially inside a particular cell, and also intersect with a ray. However, if the
intersection doesn&amp;rsquo;t occur inside that cell, then we shouldn&amp;rsquo;t count this
intersection.&lt;/p&gt;

&lt;p&gt;The algorithm is fast because it&amp;rsquo;s computationally cheap to iterate through the
cells in the grid that intersect with the ray. This is done using the
&lt;a href=&#34;https://en.wikipedia.org/wiki/Digital_differential_analyzer_(graphics_algorithm)&#34;&gt;DAA&lt;/a&gt;
method.&lt;/p&gt;

&lt;p&gt;The following is an example of the grid traversal:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://peterstace.io/static/images/grid/traverse.svg&#34; alt=&#34;Grid Traversal&#34; /&gt;&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;The first cell the ray enters is &lt;em&gt;(0, 3)&lt;/em&gt;. There is a single object in the
cell, but it doesn&amp;rsquo;t intersect with the ray. So we continue to the next
cell.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The next cell the ray enters is &lt;em&gt;(1, 3)&lt;/em&gt;. There are two objects in the cell.
The ray doesn&amp;rsquo;t intersect with the circle. However, there is also a triangle
in the cell (just a small part of its corner). The ray &lt;em&gt;does&lt;/em&gt; intersect with
the triangle, but &lt;em&gt;not&lt;/em&gt; inside the cell we are currently in (this is the edge case
describe previously). We ignore this intersection and continue on to the next cell.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The next cell the ray enters is &lt;em&gt;(1, 2)&lt;/em&gt;. There are no objects in this cell,
so we continue to the next cell.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The next cell is &lt;em&gt;(2, 2)&lt;/em&gt;. There are two objects in this cell, both
intersecting with the ray. The closest intersection is the circle. Since we
have found a valid intersection, the global ray intersection check is complete.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;performance-improvements-and-computational-complexity&#34;&gt;Performance Improvements and Computational Complexity&lt;/h2&gt;

&lt;p&gt;The rendering time for my existing scenes was decreased by a factor between 1.5
and 100 (depending on the size scene being rendered). Anecdotally, I found that
the acceleration structure had a bigger impact on scenes containing more
objects (10s or 100s of thousands). For scenes with only a few dozen objects,
the acceleration structure had only a minor effect.&lt;/p&gt;

&lt;p&gt;The computational complexity of the naive global ray intersection test is
linear in the number of objects in the scene. This is fairly obvious, since we
iterate through each object in the scene, checking for an intersection. Each
object ray intersection test is constant time on its own.&lt;/p&gt;

&lt;p&gt;I haven&amp;rsquo;t performed any formal computational complexity analysis of the grid
algorithm. Assuming that the objects in the scene are evenly distributed, I
suspect that the computational complexity is &lt;code&gt;O(n^(1/3))&lt;/code&gt; (where &lt;code&gt;n&lt;/code&gt; is the
number of objects in the scene). We are essentially iterating through a one
dimensional sequence of grid cells in a 3 dimensional grid. So we only need to
visit &lt;code&gt;O(m^(1/3))&lt;/code&gt; cells (where &lt;code&gt;m&lt;/code&gt; is the total number of cells). It follows
that if there are &lt;code&gt;n&lt;/code&gt; objects in the scene, then we would only have to perform
&lt;code&gt;O(n^(1/3))&lt;/code&gt; individual object ray intersect test per global ray intersection
test.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Path Tracing Part 2 - Depth of Field</title>
      <link>http://peterstace.io/post/2016-12-21-path-tracing-part-02-depth-of-field/</link>
      <pubDate>Wed, 21 Dec 2016 19:03:38 +1100</pubDate>
      
      <guid>http://peterstace.io/post/2016-12-21-path-tracing-part-02-depth-of-field/</guid>
      <description>&lt;p&gt;Real world cameras can only focus on objects that are a set distance away from
them. This distance is known as the &lt;em&gt;subject distance&lt;/em&gt;. Objects at other
distances will appear more or less out of focus, depending on how far away they
are from this point. Objects closer to the camera than the subject distance
will appear out of focus, as will objects beyond the subject distance. Objects
closer to the subject distance (but still not precisely at it) will still be
out of focus, but to a much lesser degree.&lt;/p&gt;

&lt;p&gt;Real world cameras can also control the degree to which parts of the image are
out of focus. Typically this is done by adjusting the &lt;em&gt;focal ratio&lt;/em&gt; of the
camera lens. This is the ratio between the focal length of the lens (distance
from lens to image sensor or film) and the lens&amp;rsquo; aperture diameter. The focal
ratio is also known as the &lt;em&gt;f-stop&lt;/em&gt; or &lt;em&gt;f-number&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Depth of field effects can be simulated in a path tracer by modifying how rays
are cast out of the virtual camera. The rays can be perturbed randomly to
simulate light passing through the camera aperture at different points.&lt;/p&gt;

&lt;p&gt;Depth of field effects have now been implemented in my path tracer,
&lt;a href=&#34;https://github.com/peterstace/grayt&#34;&gt;Grayt&lt;/a&gt;. It generated the 9 images below.
Each image is a rendering of the same scene, but with varying subject distances
and focal ratios.&lt;/p&gt;

&lt;table style=&#34;border:1px solid black;border-collapse:collapse;text-align:center&#34;&gt;
  &lt;tr&gt;
    &lt;td rowspan=&#34;2&#34; style=&#34;border:1px solid black&#34;&gt;Focal Ratio&lt;/td&gt;
    &lt;td colspan=&#34;3&#34; style=&#34;border:1px solid black&#34;&gt;Subject Distance&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;/td&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Close&lt;/td&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Mid&lt;/td&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Far&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Shallow&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/near_50.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/mid_50.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/far_50.jpg&#34; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Medium&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/near_15.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/mid_15.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/far_15.jpg&#34; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td style=&#34;border:1px solid black&#34;&gt;Deep&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/near_5.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/mid_5.jpg&#34; /&gt;&lt;/td&gt;
    &lt;td&gt;&lt;img src=&#34;http://peterstace.io/static/images/focus/far_5.jpg&#34; /&gt;&lt;/td&gt;
  &lt;/tr&gt;
&lt;/table&gt;
</description>
    </item>
    
  </channel>
</rss>